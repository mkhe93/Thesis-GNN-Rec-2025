# Model and Dataset
model: "SGL"
checkpoint_dir: 'hyper/saved'         # (str) The path to save checkpoint file.

field_separator: "\t"
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
TIME_FIELD: timestamp
user_inter_num_interval: "[20,inf)"
load_col:
    inter: [user_id, item_id]
normalize_all: false

# Evaluation
eval_args:                            # (dict) 4 keys: group_by, order, split, and mode
  split: { 'RS':[0.7,0.1,0.2] }   # (dict) The splitting strategy ranging in ['RS','LS'].{'RS':[0.8,0.1,0.1]}
  group_by: None                      # (str) The grouping strategy ranging in ['user', 'none'].
  order: RO                           # (str) The ordering strategy ranging in ['RO', 'TO'].
  mode: full

eval_step: 2
save_step: 2
stopping_step: 10

# permanent
shuffle: False
eval_batch_size: 2048           # (int) The training batch size.
train_batch_size: 2048          # (int) The training batch size.
learner: adam                   # (str) The name of used optimizer.
show_progress: False
valid_metric: "ndcg@10"


train_neg_sample_args:          # (dict) Negative sampling configuration for model training.
  distribution: uniform         # (str) The distribution of negative items.
  sample_num: 1                 # (int) The sampled num of negative items.
  alpha: 1.0                    # (float) The power of sampling probability for popularity distribution.
  dynamic: False                # (bool) Whether to use dynamic negative sampling.
  candidate_num: 1              # (int) The number of candidate negative items when dynamic negative sampling.